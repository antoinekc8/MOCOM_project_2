{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0149d6b9",
   "metadata": {},
   "source": [
    "# RL Agent traffic light control (SUMO + TraCI + PyTorch)\n",
    "\n",
    "This notebook trains and evaluates an **RL agent** for traffic control using a simple neural network.\n",
    "\n",
    "## Algorithm Overview\n",
    "\n",
    "The RL Agent learning approach:\n",
    "1. **Brain (Neural Network)**: A small PyTorch network that takes queue state (4 inputs) and outputs action probabilities (2 actions)\n",
    "2. **State**: Normalized incoming vehicle counts from 4 directions (N, S, E, W)\n",
    "3. **Action**: Binary choice - phase 0 (N-S green) or phase 2 (E-W green)\n",
    "4. **Reward**: Negative of average waiting time (lower waiting = higher reward)\n",
    "5. **Safety**: Yellow phase enforced between transitions\n",
    "\n",
    "## Workflow\n",
    "1. **Training Phase**: Learn policy from trial-and-error over multiple episodes\n",
    "2. **Evaluation Phase**: Test trained agent on fresh scenario\n",
    "3. **KPI Analysis**: Report metrics compared to baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9457ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# ==========================================\n",
    "# DEVICE SELECTION (CPU/GPU)\n",
    "# ==========================================\n",
    "# Check if CUDA (NVIDIA GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    # Ask user for device selection\n",
    "    use_gpu = input(\"\\nDo you want to use GPU for training? (y/n): \").strip().lower()\n",
    "    if use_gpu == 'y':\n",
    "        device = torch.device('cuda')\n",
    "        print(f\"\\n✓ Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print(\"\\n✓ Using CPU\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device('cpu')\n",
    "    print(\"\\n✓ Using CPU\")\n",
    "\n",
    "print(f\"\\nSelected device: {device}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f502f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SUMO binary: C:\\Program Files (x86)\\Eclipse\\Sumo\\bin\\sumo-gui.exe\n",
      "\n",
      "======================================================================\n",
      "RL AGENT TRAINING STARTED\n",
      "======================================================================\n",
      "\n",
      "--- Episode 1/5 ---\n",
      "Episode 1 completed: avg_reward = -14.3365\n",
      "\n",
      "--- Episode 2/5 ---\n",
      "Episode 2 completed: avg_reward = -15.1301\n",
      "\n",
      "--- Episode 3/5 ---\n",
      "Episode 3 completed: avg_reward = -13.7541\n",
      "\n",
      "--- Episode 4/5 ---\n",
      "Episode 4 completed: avg_reward = -14.7695\n",
      "\n",
      "--- Episode 5/5 ---\n",
      "Episode 5 completed: avg_reward = -13.5166\n",
      "Model saved to c:\\Users\\antoi\\OneDrive\\Documents\\Documents\\Devoirs\\Études sup\\ENTPE 3A\\Majeure transports\\Mobility Control and Management\\Project\\Livrable 2\\MOCOM_project_2\\Network with RL control\\models\\traffic_agent.pth\n",
      "\n",
      "======================================================================\n",
      "TRAINING COMPLETED\n",
      "======================================================================\n",
      "\n",
      "Training log summary:\n",
      "  Episode 1: avg_reward = -14.3365\n",
      "  Episode 2: avg_reward = -15.1301\n",
      "  Episode 3: avg_reward = -13.7541\n",
      "  Episode 4: avg_reward = -14.7695\n",
      "  Episode 5: avg_reward = -13.5166\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import subprocess\n",
    "import socket\n",
    "\n",
    "# ==========================================\n",
    "# 1. NEURAL NETWORK BRAIN\n",
    "# ==========================================\n",
    "class TrafficBrain(nn.Module):\n",
    "    \"\"\"Simple 2-layer neural network for traffic light control.\"\"\"\n",
    "    def __init__(self, input_size=4, hidden_size=32, output_size=2, device='cpu'):\n",
    "        super(TrafficBrain, self).__init__()\n",
    "        self.device = device\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return torch.softmax(x, dim=-1)\n",
    "    \n",
    "    def save(self, filepath):\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        torch.save(self.state_dict(), filepath)\n",
    "        print(f\"Model saved to {filepath}\")\n",
    "    \n",
    "    def load(self, filepath, device='cpu'):\n",
    "        if os.path.exists(filepath):\n",
    "            self.load_state_dict(torch.load(filepath, map_location=device))\n",
    "            print(f\"Model loaded from {filepath}\")\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. CONFIGURATION (RL TRAINING)\n",
    "# ==========================================\n",
    "BASE_DIR = os.getcwd()\n",
    "SCENARIO_DIR = os.path.join(BASE_DIR, \"Network with RL control\")\n",
    "RESULTS_DIR = os.path.join(SCENARIO_DIR, \"results\")\n",
    "CONFIG_PATH = os.path.join(SCENARIO_DIR, \"ff_heterogeneous.sumocfg\")\n",
    "MODEL_DIR = os.path.join(SCENARIO_DIR, \"models\")\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"traffic_agent.pth\")\n",
    "\n",
    "if not os.path.exists(SCENARIO_DIR):\n",
    "    # Create directory structure if it doesn't exist\n",
    "    print(f\"Creating scenario folder: {SCENARIO_DIR}\")\n",
    "    os.makedirs(SCENARIO_DIR, exist_ok=True)\n",
    "    # Copy network files from original network\n",
    "    import shutil\n",
    "    original_dir = os.path.join(BASE_DIR, \"Original network\")\n",
    "    for file in [\"ff_heterogeneous.sumocfg\", \"ff.net.xml\", \"ff_heterogeneous.rou.xml\"]:\n",
    "        src = os.path.join(original_dir, file)\n",
    "        dst = os.path.join(SCENARIO_DIR, file)\n",
    "        if os.path.exists(src):\n",
    "            shutil.copy(src, dst)\n",
    "            print(f\"Copied {file}\")\n",
    "\n",
    "if not os.path.exists(RESULTS_DIR):\n",
    "    print(f\"Creating results folder: {RESULTS_DIR}\")\n",
    "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(CONFIG_PATH):\n",
    "    sys.exit(f\"Config file not found: {CONFIG_PATH}\")\n",
    "\n",
    "# SUMO tools\n",
    "if 'SUMO_HOME' in os.environ:\n",
    "    tools = os.path.join(os.environ['SUMO_HOME'], 'tools')\n",
    "    sys.path.append(tools)\n",
    "else:\n",
    "    sys.exit(\"Please declare environment variable 'SUMO_HOME'\")\n",
    "\n",
    "import traci\n",
    "\n",
    "# SUMO binary resolution (headless mode for faster training)\n",
    "sumoBinary = \"sumo\"\n",
    "if 'SUMO_HOME' in os.environ:\n",
    "    candidate = os.path.join(os.environ['SUMO_HOME'], 'bin', 'sumo.exe')\n",
    "    if os.path.exists(candidate):\n",
    "        sumoBinary = candidate\n",
    "    else:\n",
    "        candidate = os.path.join(os.environ['SUMO_HOME'], 'bin', 'sumo')\n",
    "        if os.path.exists(candidate):\n",
    "            sumoBinary = candidate\n",
    "\n",
    "if not os.path.exists(sumoBinary):\n",
    "    try:\n",
    "        from sumolib import checkBinary\n",
    "        sumoBinary = checkBinary(\"sumo\")\n",
    "    except Exception:\n",
    "        sumoBinary = \"sumo\"\n",
    "\n",
    "print(f\"Using SUMO binary: {sumoBinary}\")\n",
    "\n",
    "# Logs - save in results folder\n",
    "sumo_log = os.path.join(RESULTS_DIR, \"sumo_log.txt\")\n",
    "sumo_err = os.path.join(RESULTS_DIR, \"sumo_err.txt\")\n",
    "traci_stdout = os.path.join(RESULTS_DIR, \"traci_stdout.txt\")\n",
    "\n",
    "# Output files - save in results folder\n",
    "EDGE_DATA_PATH = os.path.join(RESULTS_DIR, \"edge_data.xml\")\n",
    "\n",
    "\n",
    "def get_free_port():\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.bind((\"localhost\", 0))\n",
    "        return s.getsockname()[1]\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "NUM_EPISODES = 1000  # Number of training episodes\n",
    "EPISODE_DURATION = 3600  # seconds\n",
    "YELLOW_DURATION = 3  # seconds\n",
    "MIN_GREEN = 5  # seconds\n",
    "DISCOUNT_FACTOR = 0.99\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "TLS_IDS = [\"E1\", \"E2\", \"E3\", \"E4\"]\n",
    "\n",
    "\n",
    "def start_sumo(episode_num, mode=\"train\"):\n",
    "    output_file = os.path.join(RESULTS_DIR, f\"tripinfo_{mode}_ep{episode_num}.xml\")\n",
    "    log_handle = open(traci_stdout, \"a\", encoding=\"utf-8\")\n",
    "    \n",
    "    sumoCmd = [\n",
    "        sumoBinary,\n",
    "        \"-c\", CONFIG_PATH,\n",
    "        \"--quit-on-end\",\n",
    "        \"--no-step-log\",  # Disable step logging for faster execution\n",
    "        \"--tripinfo-output\", output_file,\n",
    "        \"--emission-output\", os.path.join(RESULTS_DIR, f\"emissions_{mode}_ep{episode_num}.xml\"),\n",
    "        \"--edgedata-output\", os.path.join(RESULTS_DIR, f\"edge_data_{mode}_ep{episode_num}.xml\"),\n",
    "        \"--log\", sumo_log,\n",
    "        \"--error-log\", sumo_err,\n",
    "        \"--remote-port\", str(get_free_port())\n",
    "    ]\n",
    "    \n",
    "    proc = subprocess.Popen(\n",
    "        sumoCmd,\n",
    "        cwd=SCENARIO_DIR,\n",
    "        stdout=log_handle,\n",
    "        stderr=log_handle\n",
    "    )\n",
    "    return proc, log_handle, sumoCmd[-1]\n",
    "\n",
    "\n",
    "def connect_traci(port_str, timeout_s=10):\n",
    "    port = int(port_str)\n",
    "    deadline = time.time() + timeout_s\n",
    "    last_error = None\n",
    "    while time.time() < deadline:\n",
    "        try:\n",
    "            return traci.connect(port=port, host=\"localhost\", numRetries=0, waitBetweenRetries=0)\n",
    "        except Exception as e:\n",
    "            last_error = e\n",
    "            time.sleep(0.2)\n",
    "    raise RuntimeError(f\"Could not connect. Last error: {last_error}\")\n",
    "\n",
    "\n",
    "def set_safe_phase(conn, tls_id, target_phase):\n",
    "    \"\"\"\n",
    "    Safely transition to target phase with yellow light.\n",
    "    Returns: timesteps spent in yellow\n",
    "    \"\"\"\n",
    "    current_phase = conn.trafficlight.getPhase(tls_id)\n",
    "    if current_phase == target_phase:\n",
    "        return 0\n",
    "    \n",
    "    # Go to yellow phase\n",
    "    conn.trafficlight.setPhase(tls_id, current_phase + 1)\n",
    "    for _ in range(YELLOW_DURATION):\n",
    "        conn.simulationStep()\n",
    "    \n",
    "    # Go to target phase\n",
    "    conn.trafficlight.setPhase(tls_id, target_phase)\n",
    "    return YELLOW_DURATION\n",
    "\n",
    "\n",
    "def get_state(conn):\n",
    "    \"\"\"\n",
    "    Get current state: queue lengths on incoming lanes normalized by 50.\n",
    "    Returns: torch.FloatTensor of shape (1,) on the selected device\n",
    "    \"\"\"\n",
    "    # Count vehicles in queue (halting) on each approach\n",
    "    lanes = conn.trafficlight.getControlledLanes(\"E1\")\n",
    "    queue_count = sum(conn.lane.getLastStepHaltingNumber(lane) for lane in lanes)\n",
    "    \n",
    "    # Simple state: normalize queue count and move to device\n",
    "    state = torch.FloatTensor([queue_count / 50.0]).to(device)\n",
    "    return state\n",
    "\n",
    "\n",
    "def get_reward(conn):\n",
    "    \"\"\"\n",
    "    Calculate reward based on queue length.\n",
    "    Reward = -queue_count (we want to minimize queues).\n",
    "    Lower queue = higher reward.\n",
    "    \"\"\"\n",
    "    lanes = conn.trafficlight.getControlledLanes(\"E1\")\n",
    "    queue_count = sum(conn.lane.getLastStepHaltingNumber(lane) for lane in lanes)\n",
    "    \n",
    "    # Reward is negative of queue count: fewer vehicles waiting = higher reward\n",
    "    reward = -float(queue_count)\n",
    "    return reward\n",
    "\n",
    "\n",
    "def train_rl_agent():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RL AGENT TRAINING STARTED (HEADLESS MODE)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Training {NUM_EPISODES} episodes without GUI visualization\")\n",
    "    print(\"This will be significantly faster than GUI mode.\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Initialize brain and optimizer\n",
    "    brain = TrafficBrain(input_size=1, hidden_size=16, output_size=2, device=device).to(device)\n",
    "    optimizer = optim.Adam(brain.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    training_log = []\n",
    "    \n",
    "    for episode in range(NUM_EPISODES):\n",
    "        print(f\"\\n--- Episode {episode + 1}/{NUM_EPISODES} ---\")\n",
    "        \n",
    "        proc = None\n",
    "        log_handle = None\n",
    "        conn = None\n",
    "        port_str = None\n",
    "        \n",
    "        try:\n",
    "            proc, log_handle, port_str = start_sumo(episode, mode=\"train\")\n",
    "            time.sleep(1)  # Reduced wait time for headless mode\n",
    "            conn = connect_traci(port_str, timeout_s=10)\n",
    "            \n",
    "            # Initialize traffic light\n",
    "            for tls in TLS_IDS:\n",
    "                conn.trafficlight.setProgram(tls, \"0\")\n",
    "            \n",
    "            episode_reward = 0\n",
    "            episode_steps = 0\n",
    "            phase_times = {tls: 0 for tls in TLS_IDS}\n",
    "            action_history = []\n",
    "            \n",
    "            brain.train()\n",
    "            \n",
    "            while conn.simulation.getTime() <= EPISODE_DURATION:\n",
    "                conn.simulationStep()\n",
    "                sim_time = conn.simulation.getTime()\n",
    "                \n",
    "                # Decision every 10 steps (not every step to reduce overhead)\n",
    "                if int(sim_time) % 10 == 0:\n",
    "                    state = get_state(conn)\n",
    "                    reward = get_reward(conn)\n",
    "                    episode_reward += reward\n",
    "                    \n",
    "                    # Forward pass through brain\n",
    "                    with torch.no_grad():\n",
    "                        probs = brain(state)\n",
    "                    \n",
    "                    # Choose action (0=N-S, 1=E-W)\n",
    "                    action = torch.argmax(probs).item()\n",
    "                    target_phase = 0 if action == 0 else 2\n",
    "                    \n",
    "                    # Check if enough time in current phase\n",
    "                    if phase_times[\"E1\"] >= MIN_GREEN:\n",
    "                        # Apply action\n",
    "                        set_safe_phase(conn, \"E1\", target_phase)\n",
    "                        phase_times[\"E1\"] = 0\n",
    "                    else:\n",
    "                        phase_times[\"E1\"] += 1\n",
    "                    \n",
    "                    action_history.append(action)\n",
    "                    \n",
    "                    # Training step: policy gradient\n",
    "                    probs = brain(state)  # Recompute for gradient\n",
    "                    action_prob = probs[action]\n",
    "                    loss = -torch.log(action_prob + 1e-8) * reward\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                episode_steps += 1\n",
    "            \n",
    "            avg_episode_reward = episode_reward / episode_steps if episode_steps > 0 else 0\n",
    "            training_log.append({\n",
    "                'episode': episode + 1,\n",
    "                'avg_reward': avg_episode_reward,\n",
    "                'total_reward': episode_reward,\n",
    "                'steps': episode_steps\n",
    "            })\n",
    "            \n",
    "            print(f\"Episode {episode + 1} completed: avg_reward = {avg_episode_reward:.4f}\")\n",
    "            \n",
    "            # Save model periodically\n",
    "            if (episode + 1) % 50 == 0:\n",
    "                checkpoint_path = os.path.join(MODEL_DIR, f\"traffic_agent_ep{episode + 1}.pth\")\n",
    "                brain.save(checkpoint_path)\n",
    "            \n",
    "            if conn is not None:\n",
    "                conn.close()\n",
    "            if proc is not None:\n",
    "                proc.wait(timeout=5)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Episode {episode + 1} failed: {e}\")\n",
    "        \n",
    "        finally:\n",
    "            if conn is not None:\n",
    "                try:\n",
    "                    conn.close()\n",
    "                except:\n",
    "                    pass\n",
    "            if proc is not None and proc.poll() is None:\n",
    "                proc.terminate()\n",
    "            if log_handle:\n",
    "                log_handle.close()\n",
    "    \n",
    "    # Save trained model\n",
    "    brain.save(MODEL_PATH)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING COMPLETED\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return brain, training_log\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "try:\n",
    "    brain, training_log = train_rl_agent()\n",
    "    print(f\"\\nTraining log summary:\")\n",
    "    for log_entry in training_log:\n",
    "        print(f\"  Episode {log_entry['episode']}: avg_reward = {log_entry['avg_reward']:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Training failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27118339",
   "metadata": {},
   "source": [
    "## Evaluation Phase\n",
    "\n",
    "Test the trained agent on a fresh scenario and compare against baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff5f3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RL AGENT EVALUATION\n",
      "======================================================================\n",
      "Model loaded from c:\\Users\\antoi\\OneDrive\\Documents\\Documents\\Devoirs\\Études sup\\ENTPE 3A\\Majeure transports\\Mobility Control and Management\\Project\\Livrable 2\\MOCOM_project_2\\Network with RL control\\models\\traffic_agent.pth\n",
      "\n",
      "Running evaluation simulation...\n",
      "Evaluation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# EVALUATION: Run trained agent\n",
    "# ==========================================\n",
    "\n",
    "def evaluate_rl_agent():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RL AGENT EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load trained model\n",
    "    brain = TrafficBrain(input_size=1, hidden_size=16, output_size=2, device=device).to(device)\n",
    "    if not brain.load(MODEL_PATH, device=device):\n",
    "        print(\"ERROR: Trained model not found! Run training cell first.\")\n",
    "        return\n",
    "    \n",
    "    brain.eval()\n",
    "    \n",
    "    proc = None\n",
    "    log_handle = None\n",
    "    conn = None\n",
    "    \n",
    "    try:\n",
    "        proc, log_handle, port_str = start_sumo(episode_num=999, mode=\"eval\")\n",
    "        time.sleep(2)\n",
    "        conn = connect_traci(port_str, timeout_s=10)\n",
    "        \n",
    "        # Initialize traffic light\n",
    "        for tls in TLS_IDS:\n",
    "            conn.trafficlight.setProgram(tls, \"0\")\n",
    "        \n",
    "        phase_times = {tls: 0 for tls in TLS_IDS}\n",
    "        \n",
    "        print(\"\\nRunning evaluation simulation...\")\n",
    "        \n",
    "        while conn.simulation.getTime() <= EPISODE_DURATION:\n",
    "            conn.simulationStep()\n",
    "            sim_time = conn.simulation.getTime()\n",
    "            \n",
    "            # Decision every 10 steps\n",
    "            if int(sim_time) % 10 == 0:\n",
    "                state = get_state(conn)\n",
    "                \n",
    "                # Forward pass (no gradient needed)\n",
    "                with torch.no_grad():\n",
    "                    probs = brain(state)\n",
    "                    action = torch.argmax(probs).item()\n",
    "                \n",
    "                target_phase = 0 if action == 0 else 2\n",
    "                \n",
    "                if phase_times[\"E1\"] >= MIN_GREEN:\n",
    "                    set_safe_phase(conn, \"E1\", target_phase)\n",
    "                    phase_times[\"E1\"] = 0\n",
    "                else:\n",
    "                    phase_times[\"E1\"] += 1\n",
    "        \n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "        if proc is not None:\n",
    "            proc.wait(timeout=5)\n",
    "        \n",
    "        print(\"Evaluation completed successfully!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Evaluation failed: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            try:\n",
    "                conn.close()\n",
    "            except:\n",
    "                pass\n",
    "        if proc is not None and proc.poll() is None:\n",
    "            proc.terminate()\n",
    "        if log_handle:\n",
    "            log_handle.close()\n",
    "\n",
    "\n",
    "try:\n",
    "    evaluate_rl_agent()\n",
    "except Exception as e:\n",
    "    print(f\"Evaluation error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417bdf93",
   "metadata": {},
   "source": [
    "## KPI summary for the RL agent scenario\n",
    "\n",
    "This section reads the evaluation outputs stored in **Network with RL control/results** and reports key indicators plus comprehensive visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "BASE_DIR = os.getcwd()\n",
    "SCENARIO_DIR = os.path.join(BASE_DIR, \"Network with RL control\")\n",
    "RESULTS_DIR = os.path.join(SCENARIO_DIR, \"results\")\n",
    "\n",
    "# Definition of the two directions\n",
    "DIR_A_EDGES = [\"E0E1\", \"E1E2\", \"E2E3\", \"E3E4\", \"E4E5\"]  # Forward (E0 -> E5)\n",
    "DIR_B_EDGES = [\"E5E4\", \"E4E3\", \"E3E2\", \"E2E1\", \"E1E0\"]  # Backward (E5 -> E0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b527fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. VEHICLE CLASSIFICATION\n",
    "# ==========================================\n",
    "def classify_vehicle(veh_id):\n",
    "    \"\"\"Classify vehicles based on their ID prefix.\"\"\"\n",
    "    prefix = veh_id.split('.')[0] if '.' in veh_id else veh_id\n",
    "    \n",
    "    # --- Direction A (E0 -> E5) ---\n",
    "    if prefix in ['f_7']: \n",
    "        return \"Bus Dir A (E0->E5)\", \"Bus\", \"Dir A\"\n",
    "    \n",
    "    # --- Direction B (E5 -> E0) ---\n",
    "    elif prefix in ['f_6']: \n",
    "        return \"Bus Dir B (E5->E0)\", \"Bus\", \"Dir B\"\n",
    "        \n",
    "    # --- Other categories ---\n",
    "    elif prefix in ['f_4', 'f_5']:\n",
    "        return \"Other Bus\", \"Bus\", \"Other\"\n",
    "    elif prefix in ['f_0', 'f_1', 'f_2', 'f_3']:\n",
    "        return \"Transversal Traffic\", \"Traffic\", \"Transversal\"\n",
    "    else:\n",
    "        return \"Background\", \"Car\", \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00043fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. DATA LOADING\n",
    "# ==========================================\n",
    "def load_data(data_folder):\n",
    "    \"\"\"Load trip and edge data from XML files (evaluation results).\"\"\"\n",
    "    trip_path = os.path.join(data_folder, \"tripinfo_eval_ep999.xml\")\n",
    "    edge_path = os.path.join(data_folder, \"edge_data_eval_ep999.xml\")\n",
    "\n",
    "    # --- 1. TRIPINFO (Individual vehicles) ---\n",
    "    trips = []\n",
    "    if os.path.exists(trip_path):\n",
    "        tree = ET.parse(trip_path)\n",
    "        for t in tree.getroot().findall('tripinfo'):\n",
    "            cat, vtype, route_group = classify_vehicle(t.get('id'))\n",
    "            \n",
    "            duration = float(t.get('duration'))\n",
    "            route_len = float(t.get('routeLength', 0))\n",
    "            \n",
    "            # Calculate average trip speed in km/h\n",
    "            speed_kmh = (route_len / duration) * 3.6 if duration > 0 else 0\n",
    "\n",
    "            trips.append({\n",
    "                'id': t.get('id'),\n",
    "                'category': cat,\n",
    "                'type': vtype,\n",
    "                'route_group': route_group,\n",
    "                'waitingTime': float(t.get('waitingTime')),\n",
    "                'duration': duration,\n",
    "                'routeLength': route_len,\n",
    "                'speed_kmh': speed_kmh\n",
    "            })\n",
    "    df_trips = pd.DataFrame(trips)\n",
    "\n",
    "    # --- 2. EDGE DATA (Roads) ---\n",
    "    edges_stats = []\n",
    "    if os.path.exists(edge_path):\n",
    "        tree = ET.parse(edge_path)\n",
    "        intervals = tree.getroot().findall('interval')\n",
    "        if intervals:\n",
    "            # Use the last interval\n",
    "            for e in intervals[-1].findall('edge'):\n",
    "                eid = e.get('id')\n",
    "                direction = \"None\"\n",
    "                order = 99\n",
    "                \n",
    "                if eid in DIR_A_EDGES:\n",
    "                    direction = \"Dir A (E0->E5)\"\n",
    "                    order = DIR_A_EDGES.index(eid)\n",
    "                elif eid in DIR_B_EDGES:\n",
    "                    direction = \"Dir B (E5->E0)\"\n",
    "                    order = DIR_B_EDGES.index(eid)\n",
    "                \n",
    "                if direction != \"None\":\n",
    "                    speed_ms = float(e.get('speed', 0))\n",
    "                    wait_sec = float(e.get('waitingTime', 0)) \n",
    "                    \n",
    "                    edges_stats.append({\n",
    "                        'edge_id': eid,\n",
    "                        'direction': direction,\n",
    "                        'order': order,\n",
    "                        'speed_kmh': speed_ms * 3.6,        # m/s -> km/h\n",
    "                        'waiting_hours': wait_sec / 3600.0, # seconds -> hours\n",
    "                        'density': float(e.get('density', 0))\n",
    "                    })\n",
    "    \n",
    "    df_edges = pd.DataFrame(edges_stats)\n",
    "    if not df_edges.empty:\n",
    "        df_edges = df_edges.sort_values(by=['direction', 'order'])\n",
    "\n",
    "    return df_trips, df_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70838a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. VISUALIZATION\n",
    "# ==========================================\n",
    "def create_dashboard(df_trips, df_edges, output_dir):\n",
    "    \"\"\"Create comprehensive KPI dashboards.\"\"\"\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    \n",
    "    # Separate edge datasets by direction\n",
    "    df_edges_A = df_edges[df_edges['direction'] == \"Dir A (E0->E5)\"]\n",
    "    df_edges_B = df_edges[df_edges['direction'] == \"Dir B (E5->E0)\"]\n",
    "\n",
    "    # --- FIGURE 1: EDGE ANALYSIS (SPEED & WAIT) ---\n",
    "    fig1, axes = plt.subplots(3, 2, figsize=(16, 12), constrained_layout=True)\n",
    "    fig1.suptitle(\"Edge Analysis: Bidirectional Flow (km/h & Hours)\", fontsize=18, fontweight='bold')\n",
    "\n",
    "    # Column titles\n",
    "    axes[0,0].set_title(\"DIRECTION A (E0 -> E5)\", fontsize=14, color='green', fontweight='bold')\n",
    "    axes[0,1].set_title(\"DIRECTION B (E5 -> E0)\", fontsize=14, color='blue', fontweight='bold')\n",
    "\n",
    "    # ROW 1: SPEED (km/h)\n",
    "    if not df_edges_A.empty:\n",
    "        sns.lineplot(data=df_edges_A, x='edge_id', y='speed_kmh', marker='o', color='green', ax=axes[0,0], linewidth=3)\n",
    "        axes[0,0].set_ylabel(\"Speed (km/h)\")\n",
    "        for x, y in zip(range(len(df_edges_A)), df_edges_A['speed_kmh']):\n",
    "            axes[0,0].text(x, y+0.5, f\"{y:.1f}\", ha='center', color='green', fontweight='bold')\n",
    "            \n",
    "    if not df_edges_B.empty:\n",
    "        sns.lineplot(data=df_edges_B, x='edge_id', y='speed_kmh', marker='o', color='blue', ax=axes[0,1], linewidth=3)\n",
    "        axes[0,1].set_ylabel(\"\")\n",
    "        for x, y in zip(range(len(df_edges_B)), df_edges_B['speed_kmh']):\n",
    "            axes[0,1].text(x, y+0.5, f\"{y:.1f}\", ha='center', color='blue', fontweight='bold')\n",
    "\n",
    "    # ROW 2: TOTAL ACCUMULATED WAITING TIME (Hours)\n",
    "    if not df_edges_A.empty:\n",
    "        sns.barplot(data=df_edges_A, x='edge_id', y='waiting_hours', hue='edge_id', palette=\"Greens\", ax=axes[1,0], legend=False, edgecolor='black')\n",
    "        axes[1,0].set_ylabel(\"Total Accumulated Wait (Hours)\")\n",
    "        \n",
    "    if not df_edges_B.empty:\n",
    "        sns.barplot(data=df_edges_B, x='edge_id', y='waiting_hours', hue='edge_id', palette=\"Blues\", ax=axes[1,1], legend=False, edgecolor='black')\n",
    "        axes[1,1].set_ylabel(\"\")\n",
    "\n",
    "    # ROW 3: HEATMAPS (Hours)\n",
    "    if not df_edges_A.empty:\n",
    "        matrix_A = df_edges_A[['edge_id', 'waiting_hours']].set_index('edge_id').T\n",
    "        sns.heatmap(matrix_A, annot=True, fmt=\".2f\", cmap=\"Reds\", ax=axes[2,0], cbar=False)\n",
    "        axes[2,0].set_xlabel(\"Edge Sequence\")\n",
    "        \n",
    "    if not df_edges_B.empty:\n",
    "        matrix_B = df_edges_B[['edge_id', 'waiting_hours']].set_index('edge_id').T\n",
    "        sns.heatmap(matrix_B, annot=True, fmt=\".2f\", cmap=\"Reds\", ax=axes[2,1], cbar_kws={'label': 'Hours'})\n",
    "        axes[2,1].set_xlabel(\"Edge Sequence\")\n",
    "\n",
    "    plot_path_1 = os.path.join(output_dir, \"edge_analysis_bidirectional.png\")\n",
    "    plt.savefig(plot_path_1, dpi=300)\n",
    "    print(f\"Saved: {plot_path_1}\")\n",
    "\n",
    "    # --- FIGURE 2: BUS vs NETWORK COMPARISON ---\n",
    "    fig2, axes = plt.subplots(2, 2, figsize=(14, 10), constrained_layout=True)\n",
    "    fig2.suptitle(\"Strategic KPI: Bus Performance Analysis\", fontsize=16, fontweight='bold')\n",
    "\n",
    "    # 1. Waiting Time Comparison\n",
    "    target_buses = df_trips[df_trips['type'] == 'Bus']\n",
    "    if not target_buses.empty:\n",
    "        sns.barplot(data=target_buses, x='category', y='waitingTime', hue='category', palette=\"viridis\", ax=axes[0,0], legend=False)\n",
    "        axes[0,0].set_title(\"Avg Bus Trip Waiting Time (Seconds)\", fontweight='bold')\n",
    "        axes[0,0].set_ylabel(\"Seconds per Trip\")\n",
    "        for c in axes[0,0].containers:\n",
    "            axes[0,0].bar_label(c, fmt='%.1f', padding=3)\n",
    "\n",
    "    # 2. Speed Comparison\n",
    "    comp_groups = [\"Bus Dir A (E0->E5)\", \"Bus Dir B (E5->E0)\", \"Transversal Traffic\"]\n",
    "    speed_df = df_trips[df_trips['category'].isin(comp_groups)]\n",
    "    \n",
    "    if not speed_df.empty:\n",
    "        sns.boxplot(data=speed_df, x='category', y='speed_kmh', hue='category', palette=\"Set2\", ax=axes[0,1], legend=False)\n",
    "        axes[0,1].set_title(\"Speed Comparison: Bus vs Cross Traffic\", fontweight='bold')\n",
    "        axes[0,1].set_ylabel(\"Mean Trip Speed (km/h)\")\n",
    "\n",
    "    # 3. Duration Breakdown - Bottom Left\n",
    "    dur_df = df_trips.groupby('category')['duration'].mean().reset_index()\n",
    "    dur_df = dur_df[dur_df['category'].isin(comp_groups + [\"Other Bus\"])]\n",
    "    \n",
    "    if not dur_df.empty:\n",
    "        sns.barplot(data=dur_df, x='category', y='duration', hue='category', palette=\"coolwarm\", ax=axes[1,0], legend=False)\n",
    "        axes[1,0].set_title(\"Average Trip Duration\", fontweight='bold')\n",
    "        axes[1,0].set_ylabel(\"Duration (seconds)\")\n",
    "        for c in axes[1,0].containers:\n",
    "            axes[1,0].bar_label(c, fmt='%.1f', padding=3)\n",
    "\n",
    "    # 4. Text Summary Box - Bottom Right\n",
    "    axes[1,1].axis('off')\n",
    "    \n",
    "    text_str = \"KPI SUMMARY REPORT\\n\" + \"=\"*35 + \"\\n\"\n",
    "    \n",
    "    # Global network summary\n",
    "    text_str += \"GLOBAL NETWORK SUMMARY:\\n\"\n",
    "    text_str += f\"  - Total Vehicles: {len(df_trips)}\\n\"\n",
    "    text_str += f\"  - Avg Waiting:    {df_trips['waitingTime'].mean():.2f} s\\n\"\n",
    "    text_str += f\"  - Avg Speed:      {df_trips['speed_kmh'].mean():.2f} km/h\\n\"\n",
    "    text_str += \"-\"*35 + \"\\n\"\n",
    "\n",
    "    # Category breakdown\n",
    "    for cat in comp_groups:\n",
    "        subset = df_trips[df_trips['category'] == cat]\n",
    "        if not subset.empty:\n",
    "            avg_wait = subset['waitingTime'].mean()\n",
    "            avg_speed = subset['speed_kmh'].mean()\n",
    "            avg_duration = subset['duration'].mean()\n",
    "            count = len(subset)\n",
    "            text_str += f\"{cat}:\\n\"\n",
    "            text_str += f\"  - Vehicles:  {count}\\n\"\n",
    "            text_str += f\"  - Avg Speed: {avg_speed:.2f} km/h\\n\"\n",
    "            text_str += f\"  - Avg Wait:  {avg_wait:.2f} s\\n\"\n",
    "            text_str += f\"  - Avg Dur:   {avg_duration:.2f} s\\n\\n\"\n",
    "    \n",
    "    axes[1,1].text(0.05, 0.95, text_str, fontsize=10, fontfamily='monospace', verticalalignment='top', \n",
    "                   bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.5))\n",
    "\n",
    "    plot_path_2 = os.path.join(output_dir, \"kpi_analysis_performance.png\")\n",
    "    plt.savefig(plot_path_2, dpi=300)\n",
    "    print(f\"Saved: {plot_path_2}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768b3d16",
   "metadata": {},
   "source": [
    "## KPI Analysis Results\n",
    "\n",
    "This section loads and visualizes the performance data from the RL Agent evaluation (episode 999)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f39645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. EXECUTION\n",
    "# ==========================================\n",
    "print(f\"Reading data from: {RESULTS_DIR}\")\n",
    "print(f\"Saving plots to: {RESULTS_DIR}\")\n",
    "\n",
    "try:\n",
    "    trips, edges = load_data(RESULTS_DIR)\n",
    "    \n",
    "    if trips.empty:\n",
    "        print(\"\\nWARNING: No trip data found.\")\n",
    "        print(\"Please ensure the evaluation simulation has been run.\")\n",
    "        print(f\"Expected file: {os.path.join(RESULTS_DIR, 'tripinfo_eval_ep999.xml')}\")\n",
    "    else:\n",
    "        print(f\"\\nLoaded {len(trips)} trips and {len(edges)} edge records\")\n",
    "        create_dashboard(trips, edges, RESULTS_DIR)\n",
    "        print(\"\\nAnalysis completed successfully!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
